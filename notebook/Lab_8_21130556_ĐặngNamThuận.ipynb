{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMzehe0sy5wr"
      },
      "source": [
        "The main aim of this lab is to deal with the **pipeline** technique and **MultilayerPerceptron** algorithm\n",
        "\n",
        "*   **Deadline: 23:59, 06/5/2024**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4nJmxp9zGX4"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "DoVWQ8AEyc-C"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.datasets import load_iris, load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import RFE, SelectKBest, chi2\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.naive_bayes import CategoricalNB, GaussianNB, BernoulliNB, MultinomialNB, ComplementNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, KBinsDiscretizer, OneHotEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import KBinsDiscretizer, StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "%pylab inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "def my_pipeline(X, y, preprocessing, classifiers):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "    table = PrettyTable([\"Classifier\", \"Preprocessing Steps\", \"Accuracy\", \"Precision\", \"Recall\", \"F1_Score\"])\n",
        "    preprocessing_steps = [name for name, _ in preprocessing.steps]\n",
        "\n",
        "    for name, model in classifiers.items():\n",
        "        pipeline = Pipeline([\n",
        "            ('preprocessing', preprocessing),\n",
        "            ('classifier', model)\n",
        "        ])\n",
        "\n",
        "        pipeline.fit(X_train, y_train)\n",
        "        y_pred = pipeline.predict(X_test)\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        pre = precision_score(y_test, y_pred, average='macro')\n",
        "        rec = recall_score(y_test, y_pred, average='macro')\n",
        "        f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "        table.add_row([model.__class__.__name__, preprocessing_steps, acc, pre, rec, f1])\n",
        "\n",
        "    return table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_dG9SA5OhGT"
      },
      "source": [
        "#Task 1. With **iris** dataset\n",
        "*  Apply **pipeline** including preprocessing steps (i.e., **StandardScaler**, **SimpleImputer**, **feature selection**, **KBinsDiscretizer**, …) and classification algorithms (i.e., **Random forest, kNN, Naïve Bayes**).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "models = {\n",
        "    'RandomForest': RandomForestClassifier(),\n",
        "    'kNN': KNeighborsClassifier(),\n",
        "    'NaiveBayes': GaussianNB()\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "preprocessing = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('discretizer', KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')),\n",
        "    ('pca', PCA(n_components=2))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "62jExOZ952fF"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>Classifier</th>\n",
              "            <th>Preprocessing Steps</th>\n",
              "            <th>Accuracy</th>\n",
              "            <th>Precision</th>\n",
              "            <th>Recall</th>\n",
              "            <th>F1_Score</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>RandomForestClassifier</td>\n",
              "            <td>[&#x27;scaler&#x27;, &#x27;discretizer&#x27;, &#x27;pca&#x27;]</td>\n",
              "            <td>0.9666666666666667</td>\n",
              "            <td>0.9523809523809524</td>\n",
              "            <td>0.9743589743589745</td>\n",
              "            <td>0.9610256410256411</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>KNeighborsClassifier</td>\n",
              "            <td>[&#x27;scaler&#x27;, &#x27;discretizer&#x27;, &#x27;pca&#x27;]</td>\n",
              "            <td>0.9666666666666667</td>\n",
              "            <td>0.9523809523809524</td>\n",
              "            <td>0.9743589743589745</td>\n",
              "            <td>0.9610256410256411</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>GaussianNB</td>\n",
              "            <td>[&#x27;scaler&#x27;, &#x27;discretizer&#x27;, &#x27;pca&#x27;]</td>\n",
              "            <td>0.9666666666666667</td>\n",
              "            <td>0.9523809523809524</td>\n",
              "            <td>0.9743589743589745</td>\n",
              "            <td>0.9610256410256411</td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "+------------------------+----------------------------------+--------------------+--------------------+--------------------+--------------------+\n",
              "|       Classifier       |       Preprocessing Steps        |      Accuracy      |     Precision      |       Recall       |      F1_Score      |\n",
              "+------------------------+----------------------------------+--------------------+--------------------+--------------------+--------------------+\n",
              "| RandomForestClassifier | ['scaler', 'discretizer', 'pca'] | 0.9666666666666667 | 0.9523809523809524 | 0.9743589743589745 | 0.9610256410256411 |\n",
              "|  KNeighborsClassifier  | ['scaler', 'discretizer', 'pca'] | 0.9666666666666667 | 0.9523809523809524 | 0.9743589743589745 | 0.9610256410256411 |\n",
              "|       GaussianNB       | ['scaler', 'discretizer', 'pca'] | 0.9666666666666667 | 0.9523809523809524 | 0.9743589743589745 | 0.9610256410256411 |\n",
              "+------------------------+----------------------------------+--------------------+--------------------+--------------------+--------------------+"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rf_pipeline = my_pipeline(X, y, preprocessing, models)\n",
        "rf_pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNv07ARGzOUm"
      },
      "source": [
        "#Task 2. With **fashion** dataset\n",
        "*   2.1. Apply **MultilayerPerceptron** classification with 1 hidden layer\n",
        "having 10 nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "def my_MLPClassifier(X_train, X_test, y_train, y_test, h_layer_szs):\n",
        "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=h_layer_szs, random_state=1)\n",
        "    table = PrettyTable([\"AlgoName\", \"Hidden layer sizes\", \"Accuracy\", \"Precision\", \"Recall\", \"F1_Score\"])\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    pre = precision_score(y_test, y_pred, average='macro')\n",
        "    rec = recall_score(y_test, y_pred, average='macro')\n",
        "    f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "    table.add_row(['MultilayerPerceptron', h_layer_szs, acc, pre, rec, f1])\n",
        "    return table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "sOsg77IBzEyo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------------+--------------------+----------+---------------------+---------------------+---------------------+\n",
            "|       AlgoName       | Hidden layer sizes | Accuracy |      Precision      |        Recall       |       F1_Score      |\n",
            "+----------------------+--------------------+----------+---------------------+---------------------+---------------------+\n",
            "| MultilayerPerceptron |       (10,)        |  0.151   | 0.14817212558889442 | 0.16557886557886559 | 0.09551360613906014 |\n",
            "+----------------------+--------------------+----------+---------------------+---------------------+---------------------+\n"
          ]
        }
      ],
      "source": [
        "data_train = pd.read_csv('../data/fashion_train.csv')\n",
        "data_test = pd.read_csv('../data/fashion_test.csv')\n",
        "\n",
        "X_train = data_train.drop(columns=['y'])\n",
        "y_train = data_train['y']\n",
        "X_test = data_test.drop(columns=['y'])\n",
        "y_test = data_test['y']\n",
        "\n",
        "clf = my_MLPClassifier(X_train, X_test, y_train, y_test, (10,))\n",
        "print(clf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnoVB8J4vV36"
      },
      "source": [
        "*   2.2. Apply **MultilayerPerceptron** algorithm with the following settings (the first hidden layer has 250 neuron, the second one has 100 neurons)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "-ZTSvsJdvYqI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------------+--------------------+----------+--------------------+--------------------+--------------------+\n",
            "|       AlgoName       | Hidden layer sizes | Accuracy |     Precision      |       Recall       |      F1_Score      |\n",
            "+----------------------+--------------------+----------+--------------------+--------------------+--------------------+\n",
            "| MultilayerPerceptron |     (250, 100)     |  0.764   | 0.7602001475797889 | 0.7614751901798809 | 0.7573455568059595 |\n",
            "+----------------------+--------------------+----------+--------------------+--------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "clf = my_MLPClassifier(X_train, X_test, y_train, y_test, (250, 100))\n",
        "print(clf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyey-ndXvZlb"
      },
      "source": [
        "*   2.3. Find the best hyperparameters using **GridSearchCV**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "def myGridSearchCV(X_train, y_train, X_test, y_test, classifier, params):  \n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=classifier,\n",
        "        param_grid=params,\n",
        "        scoring='accuracy',\n",
        "        refit=True,\n",
        "        cv=10,\n",
        "        return_train_score=True,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    y_pred = grid_search.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='macro')\n",
        "    recall = recall_score(y_test, y_pred, average='macro')\n",
        "    f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "    algoName = classifier.__class__.__name__\n",
        "    best_params = grid_search.best_params_\n",
        "\n",
        "    return algoName, best_params, accuracy, precision, recall, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "'hidden_layer_sizes': [(150,100,50), (120,80,40), (100,50,30)],\n",
        "'max_iter': [50, 100, 150],\n",
        "'activation': ['tanh', 'relu'],\n",
        "'solver': ['sgd', 'adam'],\n",
        "'alpha': [0.0001, 0.05],\n",
        "'learning_rate': ['constant','adaptive'],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "Qzh_D-rgvbv9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classifier: MLPClassifier, Params: {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (150, 100, 50), 'learning_rate': 'constant', 'max_iter': 150, 'solver': 'sgd'}\n"
          ]
        }
      ],
      "source": [
        "algoName, best_params, accuracy, precision, recall, f1 = myGridSearchCV(X_train, y_train, X_test, y_test, MLPClassifier(random_state=1), param_grid)\n",
        "print(f\"Classifier: {algoName}, Params: {best_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "table = PrettyTable([\"Classifier with the best hyperparameters\", \"Accuracy\", \"Precision\", \"Recall\", \"F1_Score\"])\n",
        "table.add_row([algoName, accuracy, precision, recall, f1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol1U_T_NvcqV"
      },
      "source": [
        "*   2.4. Compare the **MultilayerPerceptron** using the best hyperparameters in 2.3 and other classification algorithms (i.e., Random forest, kNN, Naïve Bayes)  in termns of accuracy, precision, recall, and F1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_params = { 'n_neighbors' : [5,7,9,11,13,15],\n",
        "               'weights' : ['uniform','distance'],\n",
        "               'metric' : ['minkowski','euclidean','manhattan']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "5ZE7A0Au1Pg0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classifier: KNeighborsClassifier, Params: {'metric': 'minkowski', 'n_neighbors': 5, 'weights': 'distance'}\n"
          ]
        }
      ],
      "source": [
        "algoName, best_params, accuracy, precision, recall, f1 = myGridSearchCV(X_train, y_train, X_test, y_test, KNeighborsClassifier(), grid_params)\n",
        "print(f\"Classifier: {algoName}, Params: {best_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "table.add_row([algoName, accuracy, precision, recall, f1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [25, 50, 100, 150],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'max_leaf_nodes': [3, 6, 9],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classifier: RandomForestClassifier, Params: {'max_depth': 6, 'max_features': 'log2', 'max_leaf_nodes': 9, 'n_estimators': 100}\n"
          ]
        }
      ],
      "source": [
        "algoName, best_params, accuracy, precision, recall, f1 = myGridSearchCV(X_train, y_train, X_test, y_test, RandomForestClassifier(), param_grid)\n",
        "print(f\"Classifier: {algoName}, Params: {best_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "table.add_row([algoName, accuracy, precision, recall, f1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "table.add_row([model.__class__.__name__, accuracy, precision, recall, f1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------------------------------+----------+--------------------+--------------------+--------------------+\n",
            "| Classifier with the best hyperparameters | Accuracy |     Precision      |       Recall       |      F1_Score      |\n",
            "+------------------------------------------+----------+--------------------+--------------------+--------------------+\n",
            "|              MLPClassifier               |  0.767   | 0.7694117201272791 | 0.7656622650561749 | 0.759167966189757  |\n",
            "|           KNeighborsClassifier           |  0.761   | 0.7744516182441685 | 0.7612940338424302 | 0.7579477874924644 |\n",
            "|          RandomForestClassifier          |   0.69   | 0.6859005769763701 | 0.6899556592478538 | 0.6354385534790379 |\n",
            "|                GaussianNB                |  0.556   | 0.5788628371304589 | 0.559496772854223  | 0.5256907025966637 |\n",
            "+------------------------------------------+----------+--------------------+--------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "print(table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBSLD_k3Pk3X"
      },
      "source": [
        "#Task 3. With **breast cancer** dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1IZborjPzMH"
      },
      "source": [
        "*   3.1. Apply **GridSearchCV** to **MultilayperPerceptron** to find the best hyperparameters (the setting of hyperparameters chosen by students)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "'hidden_layer_sizes': [(150,100,50), (120,80,40), (100,50,30)],\n",
        "'max_iter': [50, 100, 150],\n",
        "'activation': ['tanh', 'relu'],\n",
        "'solver': ['sgd', 'adam'],\n",
        "'alpha': [0.0001, 0.05],\n",
        "'learning_rate': ['constant','adaptive'],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "m-mbZEK0QZTv"
      },
      "outputs": [],
      "source": [
        "cancer = load_breast_cancer(as_frame=True)\n",
        "X, y = cancer.data, cancer.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classifier: MLPClassifier, Params: {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (150, 100, 50), 'learning_rate': 'constant', 'max_iter': 50, 'solver': 'adam'}\n"
          ]
        }
      ],
      "source": [
        "algoName, best_params, accuracy, precision, recall, f1 = myGridSearchCV(X_train, y_train, X_test, y_test, MLPClassifier(random_state=1), param_grid)\n",
        "print(f\"Classifier: {algoName}, Params: {best_params}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [],
      "source": [
        "table = PrettyTable([\"Classifier with the best hyperparameters\", \"Accuracy\", \"Precision\", \"Recall\", \"F1_Score\"])\n",
        "table.add_row([algoName, accuracy, precision, recall, f1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H77rqX7sPv9v"
      },
      "source": [
        "*   3.2. Compare the **MultilayerPerceptron** using the best hyperparameters in 3.1) and other classification algorithms (i.e., Random forest, kNN, Naïve Bayes)  in termns of accuracy, precision, recall, and F1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(classifier, X_train, X_test, y_train, y_test):\n",
        "    classifier.fit(X_train, y_train.values.ravel())\n",
        "    y_pred = classifier.predict(X_test)\n",
        "\n",
        "    ac = metrics.accuracy_score(y_test, y_pred)\n",
        "    pre = metrics.precision_score(y_test, y_pred, average=\"macro\")\n",
        "    recall = metrics.recall_score(y_test, y_pred, average=\"macro\")\n",
        "    f1 = metrics.f1_score(y_test, y_pred, average=\"macro\")\n",
        "\n",
        "    return [classifier.__class__.__name__, ac, pre, recall, f1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "pBU6vVH_QakV"
      },
      "outputs": [],
      "source": [
        "table.add_row(evaluate_model(KNeighborsClassifier(n_neighbors=13, metric='manhattan', weights='uniform'), X_train, X_test, y_train, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [],
      "source": [
        "table.add_row(evaluate_model(RandomForestClassifier(max_depth=6, max_features=None, max_leaf_nodes=9, n_estimators=50), X_train, X_test, y_train, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "table.add_row(evaluate_model(GaussianNB(), X_train, X_test, y_train, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------------------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "| Classifier with the best hyperparameters |      Accuracy      |     Precision      |       Recall       |      F1_Score      |\n",
            "+------------------------------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|              MLPClassifier               | 0.9298245614035088 | 0.9412393162393162 | 0.9097222222222223 | 0.9220512820512821 |\n",
            "|           KNeighborsClassifier           | 0.9298245614035088 | 0.9412393162393162 | 0.9097222222222223 | 0.9220512820512821 |\n",
            "|          RandomForestClassifier          | 0.9649122807017544 | 0.9736842105263157 | 0.9523809523809523 | 0.9614864864864865 |\n",
            "|                GaussianNB                | 0.9473684210526315 | 0.9479729729729729 | 0.9384920634920635 | 0.942866688940862  |\n",
            "+------------------------------------------+--------------------+--------------------+--------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "print(table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JdCVnj_89Fl"
      },
      "source": [
        "#Task 4. With **mobile price classification** dataset\n",
        "\n",
        "\n",
        "*   4.1. Build your own Neural Network using **MultilayerPerceptron**  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "ePpTY6Lk9X2V"
      },
      "outputs": [],
      "source": [
        "mobile = pd.read_csv('../data/mobile.csv')\n",
        "X = mobile.drop(columns=['price_range'])\n",
        "y = mobile['price_range']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------------+--------------------+----------+--------------------+--------------------+--------------------+\n",
            "|       AlgoName       | Hidden layer sizes | Accuracy |     Precision      |       Recall       |      F1_Score      |\n",
            "+----------------------+--------------------+----------+--------------------+--------------------+--------------------+\n",
            "| MultilayerPerceptron |     (250, 100)     |  0.6025  | 0.6158269016067182 | 0.6048588323762647 | 0.6092813569733209 |\n",
            "+----------------------+--------------------+----------+--------------------+--------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "clf = my_MLPClassifier(X_train, X_test, y_train, y_test, (250, 100))\n",
        "print(clf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------------+--------------------+----------+---------------------+--------------------+--------------------+\n",
            "|       AlgoName       | Hidden layer sizes | Accuracy |      Precision      |       Recall       |      F1_Score      |\n",
            "+----------------------+--------------------+----------+---------------------+--------------------+--------------------+\n",
            "| MultilayerPerceptron |   (150, 100, 50)   |  0.3825  | 0.30566557778685177 | 0.3736242138364779 | 0.3223608363609721 |\n",
            "+----------------------+--------------------+----------+---------------------+--------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "clf = my_MLPClassifier(X_train, X_test, y_train, y_test, (150,100,50))\n",
        "print(clf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqlFS6ic9ZCV"
      },
      "source": [
        "*   4.2. Apply **GridSearchCV** to **MultilayperPerceptron** to find the best hyperparameters (the setting of hyperparameters chosen by students)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "'hidden_layer_sizes': [(150,100,50), (120,80,40), (100,50,30)],\n",
        "'max_iter': [50, 100, 150],\n",
        "'activation': ['tanh', 'relu'],\n",
        "'solver': ['sgd', 'adam'],\n",
        "'alpha': [0.0001, 0.05],\n",
        "'learning_rate': ['constant','adaptive'],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "OvW2yGUU9_ik"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classifier: MLPClassifier, Params: {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (120, 80, 40), 'learning_rate': 'constant', 'max_iter': 100, 'solver': 'adam'}\n"
          ]
        }
      ],
      "source": [
        "algoName, best_params, accuracy, precision, recall, f1 = myGridSearchCV(X_train, y_train, X_test, y_test, MLPClassifier(random_state=1), param_grid)\n",
        "print(f\"Classifier: {algoName}, Params: {best_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ok7RGkea_b7n"
      },
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
